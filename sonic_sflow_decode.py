
# Author: Jason Robinson
# Author: Mani Amoozadeh
# Github: https://github.com/auspex-labs/sflow-collector

from socket import AF_INET, AF_INET6, inet_ntop
from struct import unpack, calcsize
import logging

log = logging.getLogger(__name__)

# --- Constants for sFlow Parsing ---
# sFlow Datagram Versions
SFLOW_DATAGRAM_VERSION_5 = 5 # Standard sFlow version

# Address Types
SFLOW_ADDRESS_IPV4 = 1
SFLOW_ADDRESS_IPV6 = 2

# Sample Types (Enterprise = 0 for all standard types)
SFLOW_FLOW_SAMPLE = 1
SFLOW_COUNTER_SAMPLE = 2
SFLOW_FLOW_SAMPLE_EXPANDED = 3
SFLOW_COUNTER_SAMPLE_EXPANDED = 4

# Record Types (Enterprise = 0 for all standard types)
# Flow Records (Sample Types 1, 3)
SFLOW_FLOW_RAW_PACKET_HEADER = 1
SFLOW_FLOW_ETHERNET_FRAME = 2
SFLOW_FLOW_SAMPLED_IPV4 = 3
SFLOW_FLOW_SAMPLED_IPV6 = 4
SFLOW_FLOW_EXT_SWITCH = 1001
SFLOW_FLOW_EXT_ROUTER = 1002
SFLOW_FLOW_EXT_GATEWAY = 1003
SFLOW_FLOW_EXT_USER = 1004
SFLOW_FLOW_EXT_URL = 1005
SFLOW_FLOW_EXT_MPLS = 1006
SFLOW_FLOW_EXT_NAT = 1007
SFLOW_FLOW_EXT_MPLS_TUNNEL = 1008
SFLOW_FLOW_EXT_MPLS_VC = 1009
SFLOW_FLOW_EXT_MPLS_FTN = 1010
SFLOW_FLOW_EXT_MPLS_LDP_FEC = 1011
SFLOW_FLOW_EXT_VLAN_TUNNEL = 1012
SFLOW_FLOW_EXT_SOCKET_IPV4 = 2100
SFLOW_FLOW_EXT_SOCKET_IPV6 = 2101

# Counter Records (Sample Types 2, 4)
SFLOW_COUNTER_IF = 1
SFLOW_COUNTER_ETHERNET = 2
SFLOW_COUNTER_VLAN = 5
SFLOW_COUNTER_PROCESSOR = 1001
SFLOW_COUNTER_PORT_NAME = 1005 # Deprecated, use SNMP ifName
SFLOW_COUNTER_HOST_DESCRIPTION = 2000
SFLOW_COUNTER_HOST_ADAPTERS = 2001
SFLOW_COUNTER_HOST_PARENT = 2002
SFLOW_COUNTER_HOST_CPU = 2003
SFLOW_COUNTER_HOST_MEMORY = 2004
SFLOW_COUNTER_HOST_DISK_IO = 2005
SFLOW_COUNTER_HOST_NETWORK_IO = 2006
SFLOW_COUNTER_MIB2_IP_GROUP = 2007
SFLOW_COUNTER_MIB2_ICMP_GROUP = 2008
SFLOW_COUNTER_MIB2_TCP_GROUP = 2009
SFLOW_COUNTER_MIB2_UDP_GROUP = 2010


# Ethernet Protocol Types (common ones for parsing)
ETHERTYPE_IPV4 = 0x0800
ETHERTYPE_8021Q = 0x8100  # VLAN
ETHERTYPE_8021AD = 0x88A8 # Q-in-Q


class sFlow:
    """
    Represents an sFlow datagram.

    Attributes:
        len (int): Total length of the sFlow datagram.
        data (bytes): The raw sFlow datagram bytes.
        datagram_version (int): sFlow protocol version.
        address_type (int): Type of the agent's IP address (1 for IPv4, 2 for IPv6).
        agent_address (str): IP address of the sampling agent.
        sub_agent (int): Used to distinguish between datagram streams from separate
                         agent sub entities within a device.
        sequence_number (int): Incremented with each sample datagram generated by a sub-agent.
        system_uptime (int): Current time (in milliseconds since device last booted).
        number_sample (int): Number of samples contained in this datagram.
        samples (list): A list of sFlowSample objects.
    """

    def __init__(self, datagram: bytes):
        self.len = len(datagram)
        self.data = datagram

        # Ensure datagram is large enough for initial header
        if self.len < 28: # Minimum size for IPv4 header
            raise ValueError(f"sFlow datagram too short: {self.len} bytes")

        self.datagram_version = unpack(">i", datagram[0:4])[0]
        if self.datagram_version != SFLOW_DATAGRAM_VERSION_5:
            log.warning(f"Unsupported sFlow datagram version: {self.datagram_version}. Expected {SFLOW_DATAGRAM_VERSION_5}")
            # Potentially raise an error or handle gracefully based on desired strictness
            # For now, we proceed, but parsing might fail for non-v5.

        self.address_type = unpack(">i", datagram[4:8])[0]

        data_position = 0
        if self.address_type == SFLOW_ADDRESS_IPV4:
            self.agent_address = inet_ntop(AF_INET, datagram[8:12])
            data_position = 12
        elif self.address_type == SFLOW_ADDRESS_IPV6:
            self.agent_address = inet_ntop(AF_INET6, datagram[8:24])
            data_position = 24
        else:
            raise ValueError(f"Unknown agent address type: {self.address_type}")

        # Unpack common fields after address
        try:
            self.sub_agent = unpack(">i", datagram[data_position : data_position + 4])[0]
            self.sequence_number = unpack(">i", datagram[data_position + 4 : data_position + 8])[0]
            self.system_uptime = unpack(">i", datagram[data_position + 8 : data_position + 12])[0]
            self.number_sample = unpack(">i", datagram[data_position + 12 : data_position + 16])[0]
            data_position += 16
        except Exception as e:
            raise ValueError(f"Error unpacking common sFlow header fields: {e}")

        self.samples = []

        # Parse samples if any
        if self.number_sample > 0:
            for i in range(self.number_sample):
                try:
                    # Check if there's enough data for sample header + size
                    if data_position + 8 > self.len:
                        log.warning(f"Not enough data for sample {i+1} header. Remaining: {self.len - data_position} bytes.")
                        break

                    sample_header_raw = datagram[data_position : data_position + 4]
                    sample_size = unpack(">i", datagram[data_position + 4 : data_position + 8])[0]

                    # Check if there's enough data for the entire sample
                    if data_position + 8 + sample_size > self.len:
                        log.warning(f"Not enough data for sample {i+1} body. Expected {sample_size} bytes, got {self.len - (data_position + 8)}.")
                        break

                    sample_datagram = datagram[data_position + 8 : data_position + sample_size + 8]

                    self.samples.append(sFlowSample(sample_header_raw, sample_size, sample_datagram))
                    data_position += 8 + sample_size
                except Exception as e:
                    log.error(f"Failed to parse sFlow sample {i+1}: {e}")
                    # Attempt to skip to the next potential sample if size was corrupted,
                    # but this is tricky without knowing the true size.
                    # For now, break if one sample is unparseable to prevent infinite loops.
                    break


    def dump(self):
        """Logs the contents of the sFlow datagram and its samples/records."""
        try:
            log.info("--- sFlow Datagram ---")
            log.info("Length: %s", getattr(self, 'len', 'N/A'))
            log.info("DG Version: %s", getattr(self, 'datagram_version', 'N/A'))
            log.info("Address Type: %s", getattr(self, 'address_type', 'N/A'))
            log.info("Agent Address: %s", getattr(self, 'agent_address', 'N/A'))
            log.info("Sub Agent: %s", getattr(self, 'sub_agent', 'N/A'))
            log.info("Sequence Number: %s", getattr(self, 'sequence_number', 'N/A'))
            log.info("System UpTime: %s", getattr(self, 'system_uptime', 'N/A'))
            log.info("Number of Samples: %s", getattr(self, 'number_sample', 'N/A'))
            log.info("----------------------\n")
        except Exception as e:
            log.exception("Failed to log datagram header: %s", e)

        for i, sample in enumerate(getattr(self, 'samples', [])):
            try:
                log.info("--- Sample Number: %s ---", i + 1)
                log.info("  Sample Sequence: %s", getattr(sample, 'sequence', 'N/A'))
                log.info("  Sample Enterprise: %s", getattr(sample, 'enterprise', 'N/A'))
                log.info("  Sample Type: %s", getattr(sample, 'sample_type', 'N/A'))
                log.info("  Sample Length: %s", getattr(sample, 'len', 'N/A'))
                log.info("  Sample Dropped Packets: %s", getattr(sample, 'dropped_packets', 'N/A'))
                log.info("  Sample Record Count: %s", getattr(sample, 'record_count', 'N/A'))
                log.info("------------------------\n")
            except Exception as e:
                log.exception("Failed to log sample #%d header: %s", i + 1, e)
                continue

            for j, record in enumerate(getattr(sample, 'records', [])):
                try:
                    log.info("    --- Record Number: %s ---", j + 1)
                    log.info("    Sample Type (from parent): %s", getattr(record, 'sample_type', 'N/A'))
                    log.info("    Sample Record Enterprise: %s", getattr(record, 'enterprise', 'N/A'))
                    log.info("    Sample Record Format: %s", getattr(record, 'format', 'N/A'))

                    if hasattr(record, 'record') and record.record is not None:
                        # Use the __repr__ of the specific record type
                        log.info("    Record Data:\n%s", repr(record.record))
                    else:
                        log.info("    Record Data: N/A or not fully parsed (type: %s-%s-%s)",
                                 getattr(record, 'sample_type', 'N/A'),
                                 getattr(record, 'enterprise', 'N/A'),
                                 getattr(record, 'format', 'N/A'))

                    log.info("    ---------------------------\n")
                except Exception as e:
                    log.exception("Failed to log record #%d in sample #%d: %s", j + 1, i + 1, e)


class sFlowSample:
    """
    Represents an sFlow sample contained within an sFlow datagram.

    Attributes:
        len (int): Length of the sample data.
        data (bytes): Raw sample data bytes.
        enterprise (int): Enterprise ID of the sample type.
        sample_type (int): Type of the sample (e.g., SFLOW_FLOW_SAMPLE, SFLOW_COUNTER_SAMPLE).
        sequence (int): Incremented with each flow sample generated by this source_id.
        source_type (int): sFlowDataSource type.
        source_index (int): sFlowDataSource index.
        sample_rate (int): sFlowPacketSamplingRate (for Flow samples).
        sample_pool (int): Total number of packets that could have been sampled (for Flow samples).
        dropped_packets (int): Number of times a sampled packet was dropped due to resource limits (for Flow samples).
        input_if_format (int): Interface format packet was received on (for Flow samples).
        input_if_value (int): Interface value packet was received on (for Flow samples).
        output_if_format (int): Interface format packet was sent on (for Flow samples).
        output_if_value (int): Interface value packet was sent on (for Flow samples).
        record_count (int): Number of records in this sample.
        records (list): A list of sFlowRecord objects.
    """

    def __init__(self, header: bytes, sample_size: int, datagram: bytes):
        self.len = sample_size
        self.data = datagram

        sample_header_value = unpack(">i", header)[0]
        self.enterprise, self.sample_type = divmod(sample_header_value, 4096)

        # Minimum size check for sequence number
        if len(datagram) < 4:
            raise ValueError("Sample datagram too short for sequence number.")
        self.sequence = unpack(">i", datagram[0:4])[0]
        data_position = 4

        # Source type and index parsing varies by sample type
        if self.sample_type in [SFLOW_FLOW_SAMPLE, SFLOW_COUNTER_SAMPLE]:
            if len(datagram) < data_position + 4: raise ValueError("Sample datagram too short for source info.")
            sample_source = unpack(">i", datagram[data_position : data_position + 4])[0]
            self.source_type, self.source_index = divmod(sample_source, 16777216) # 2^24
            data_position += 4
        elif self.sample_type in [SFLOW_FLOW_SAMPLE_EXPANDED, SFLOW_COUNTER_SAMPLE_EXPANDED]:
            if len(datagram) < data_position + 8: raise ValueError("Sample datagram too short for source info (expanded).")
            self.source_type = unpack(">i", datagram[data_position : data_position + 4])[0]
            self.source_index = unpack(">i", datagram[data_position + 4 : data_position + 8])[0]
            data_position += 8
        else:
            log.warning(f"Unsupported sample type: {self.sample_type}. Skipping detailed sample parsing.")
            self.source_type = 0
            self.source_index = 0
            self.record_count = 0 # No records for unknown sample type
            self.sample_rate = 0
            self.sample_pool = 0
            self.dropped_packets = 0
            self.input_if_format = 0
            self.input_if_value = 0
            self.output_if_format = 0
            self.output_if_value = 0
            self.records = []
            return # Exit early if sample type is unknown

        self.records = []

        # Flow sample specific fields
        if self.sample_type in [SFLOW_FLOW_SAMPLE, SFLOW_FLOW_SAMPLE_EXPANDED]:
            if len(datagram) < data_position + 12: raise ValueError("Sample datagram too short for flow sample data.")
            self.sample_rate, self.sample_pool, self.dropped_packets = unpack(
                ">iii", datagram[data_position : (data_position + 12)]
            )
            data_position += 12

            # Interface fields
            if self.sample_type == SFLOW_FLOW_SAMPLE:
                if len(datagram) < data_position + 8: raise ValueError("Sample datagram too short for interface data.")
                input_interface_raw, output_interface_raw = unpack(">ii", datagram[data_position : (data_position + 8)])
                self.input_if_format, self.input_if_value = divmod(input_interface_raw, 1073741824) # 2^30
                self.output_if_format, self.output_if_value = divmod(output_interface_raw, 1073741824)
                data_position += 8
            elif self.sample_type == SFLOW_FLOW_SAMPLE_EXPANDED:
                if len(datagram) < data_position + 16: raise ValueError("Sample datagram too short for expanded interface data.")
                self.input_if_format, self.input_if_value, self.output_if_format, self.output_if_value = unpack(
                    ">iiii", datagram[data_position : (data_position + 16)]
                )
                data_position += 16

            if len(datagram) < data_position + 4: raise ValueError("Sample datagram too short for record count.")
            self.record_count = unpack(">i", datagram[data_position : data_position + 4])[0]
            data_position += 4

        # Counter sample specific fields
        elif self.sample_type in [SFLOW_COUNTER_SAMPLE, SFLOW_COUNTER_SAMPLE_EXPANDED]:
            if len(datagram) < data_position + 4: raise ValueError("Sample datagram too short for record count.")
            self.record_count = unpack(">i", datagram[data_position : (data_position + 4)])[0]
            data_position += 4
            # Counter samples don't have these fields, initialize to 0
            self.sample_rate = 0
            self.sample_pool = 0
            self.dropped_packets = 0
            self.input_if_format = 0
            self.input_if_value = 0
            self.output_if_format = 0
            self.output_if_value = 0

        # Parse records
        for i in range(self.record_count):
            try:
                if data_position + 8 > len(datagram):
                    log.warning(f"Not enough data for record {i+1} header. Remaining: {len(datagram) - data_position} bytes.")
                    break
                record_header_raw = datagram[data_position : (data_position + 4)]
                record_size = unpack(">i", datagram[(data_position + 4) : (data_position + 8)])[0]

                if data_position + 8 + record_size > len(datagram):
                    log.warning(f"Not enough data for record {i+1} body. Expected {record_size} bytes, got {len(datagram) - (data_position + 8)}.")
                    break

                record_data = datagram[(data_position + 8) : (data_position + record_size + 8)]
                self.records.append(sFlowRecord(record_header_raw, self.sample_type, record_data))
                data_position += record_size + 8
            except Exception as e:
                log.error(f"Failed to parse sFlow record {i+1} in sample: {e}")
                break


class sFlowRecordBase:
    """Base class for sFlow records, providing a default representation for unimplemented types."""
    def __init__(self, datagram: bytes):
        self.data = datagram

    def __repr__(self):
        return f"\t\t\tIncomplete or Unknown sFlow Record Type (Raw Data Length: {len(self.data)})"


# --- Flow Record Types ---

class sFlowRawPacketHeader(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 16:
            raise ValueError("RawPacketHeader datagram too short.")

        self.header_protocol = unpack(">i", datagram[0:4])[0]
        self.frame_length = unpack(">i", datagram[4:8])[0]
        self.payload_removed = unpack(">i", datagram[8:12])[0]
        self.header_size = unpack(">i", datagram[12:16])[0]
        self.header = datagram[16 : (16 + self.header_size)]

        self.destination_mac = None
        self.source_mac = None
        self.eth_type = None
        self.outer_vlan = None
        self.inner_vlan = None
        self.vlan = None
        self.ip_version = None
        self.ip_header_length = None
        self.ip_dscp = None
        self.ip_ecn = None
        self.ip_total_length = None
        self.ip_identification = None
        self.ip_flags = None
        self.ip_fragment_offset = None
        self.ip_ttl = None
        self.ip_protocol = None
        self.ip_checksum = None
        self.ip_source = None
        self.ip_destination = None
        self.ip_options = None
        self.ip_remaining_header = None

        if self.header_protocol == 1:  # Ethernet
            if len(self.header) < 14: # Minimum Ethernet header size
                log.warning("RawPacketHeader Ethernet header too short for basic parsing.")
                return

            self.destination_mac = self.header[0:6].hex(":")
            self.source_mac = self.header[6:12].hex(":")
            self.eth_type = unpack(">H", self.header[12:14])[0]

            offset = 0
            # Check for VLAN tags
            if self.eth_type == ETHERTYPE_8021AD:  # 802.1ad (Q-in-Q)
                if len(self.header) < 20: # 14 (base) + 4 (outer VLAN) + 2 (next ethertype)
                     log.warning("RawPacketHeader 802.1ad header too short for full parsing.")
                     return
                offset = 8
                self.outer_vlan = unpack(">H", self.header[14:16])[0] & 0x0FFF # VLAN ID is lower 12 bits
                # The inner VLAN type is at 18:20, and inner VLAN ID at 20:22.
                # Assuming the next 4 bytes are inner VLAN tag
                self.inner_vlan = unpack(">H", self.header[18:20])[0] & 0x0FFF
                self.eth_type = unpack(">H", self.header[20:22])[0] # The real ethertype after Q-in-Q
                if self.eth_type == ETHERTYPE_8021Q: # Handle stacked 802.1Q after 802.1ad
                     self.vlan = unpack(">H", self.header[22:24])[0] & 0x0FFF
                     self.eth_type = unpack(">H", self.header[24:26])[0] # The real ethertype after 802.1Q
                     offset += 4 # Additional 4 bytes for second 802.1Q

            elif self.eth_type == ETHERTYPE_8021Q:  # 802.1Q
                if len(self.header) < 18: # 14 (base) + 4 (VLAN)
                    log.warning("RawPacketHeader 802.1Q header too short for full parsing.")
                    return
                offset = 4
                self.vlan = unpack(">H", self.header[14:16])[0] & 0x0FFF
                self.eth_type = unpack(">H", self.header[16:18])[0] # The real ethertype after 802.1Q

            # IPv4 parsing
            if self.eth_type == ETHERTYPE_IPV4:
                ip_header_start = 14 + offset
                if len(self.header) < ip_header_start + 20: # Min IPv4 header size
                    log.warning("RawPacketHeader IPv4 header too short for basic parsing.")
                    return

                self.ip_version, self.ip_header_length = divmod(self.header[ip_header_start], 16)
                self.ip_dscp, self.ip_ecn = divmod(self.header[ip_header_start + 1], 4) # DSCP upper 6 bits, ECN lower 2
                self.ip_total_length = unpack(">H", self.header[ip_header_start + 2 : ip_header_start + 4])[0]
                self.ip_identification = unpack(">H", self.header[ip_header_start + 4 : ip_header_start + 6])[0]
                flags_fragment_offset = unpack(">H", self.header[ip_header_start + 6 : ip_header_start + 8])[0]
                self.ip_flags = (flags_fragment_offset >> 13) & 0x07 # 3 bits flags
                self.ip_fragment_offset = flags_fragment_offset & 0x1FFF # 13 bits fragment offset
                self.ip_ttl = self.header[ip_header_start + 8]
                self.ip_protocol = self.header[ip_header_start + 9]
                self.ip_checksum = unpack(">H", self.header[ip_header_start + 10 : ip_header_start + 12])[0]
                self.ip_source = inet_ntop(AF_INET, self.header[ip_header_start + 12 : ip_header_start + 16])
                self.ip_destination = inet_ntop(AF_INET, self.header[ip_header_start + 16 : ip_header_start + 20])

                if self.ip_header_length > 5: # If there are IP options
                    options_len = (self.ip_header_length - 5) * 4
                    if len(self.header) >= ip_header_start + 20 + options_len:
                        self.ip_options = self.header[ip_header_start + 20 : ip_header_start + 20 + options_len]
                    else:
                        log.warning("RawPacketHeader IPv4 options data truncated.")
                        self.ip_options = b''
                else:
                    self.ip_options = b''

                self.ip_remaining_header = self.header[ip_header_start + (self.ip_header_length * 4):]

    def __repr__(self):
        eth_info = ""
        if self.source_mac:
            eth_info = f"""
                Source MAC: {self.source_mac}
                Destination MAC: {self.destination_mac}
                EtherType: {self.eth_type:#x} ({self.eth_type})"""
            if self.outer_vlan is not None:
                eth_info += f"\n\t\t\t\tOuter VLAN: {self.outer_vlan}"
            if self.inner_vlan is not None:
                eth_info += f"\n\t\t\t\tInner VLAN: {self.inner_vlan}"
            if self.vlan is not None:
                eth_info += f"\n\t\t\t\tVLAN: {self.vlan}"

        ip_info = ""
        if self.ip_source:
            ip_info = f"""
                IP Version: {self.ip_version}
                IP Header Length: {self.ip_header_length * 4} bytes
                IP Total Length: {self.ip_total_length}
                IP DSCP: {self.ip_dscp}, ECN: {self.ip_ecn}
                IP Identification: {self.ip_identification}
                IP Flags: {self.ip_flags}, Fragment Offset: {self.ip_fragment_offset}
                IP TTL: {self.ip_ttl}
                IP Protocol: {self.ip_protocol}
                IP Checksum: {self.ip_checksum:#x}
                IP Source: {self.ip_source}
                IP Destination: {self.ip_destination}"""
            if self.ip_options:
                ip_info += f"\n\t\t\t\tIP Options: {self.ip_options.hex()}"
            if self.ip_remaining_header:
                ip_info += f"\n\t\t\t\tIP Payload Preview (first 16 bytes): {self.ip_remaining_header[:16].hex()}"

        return f"""
            Raw Packet Header:
                Header Protocol: {self.header_protocol}
                Frame Length: {self.frame_length} (Original packet length)
                Header Size: {self.header_size} (Sampled header length)
                Payload Removed: {self.payload_removed}{eth_info}{ip_info}
        """

class sFlowEthernetFrame(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 2"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 24:
            raise ValueError("EthernetFrame datagram too short.")
        self.frame_length = unpack(">i", datagram[0:4])[0]
        self.source_mac = datagram[4:10].hex(":")
        # The sFlow spec indicates 2 bytes of padding after source_mac, then dest_mac
        # However, common implementations put destination_mac immediately after source_mac
        # Assuming 6 bytes for source_mac, 2 bytes padding, 6 bytes for dest_mac
        # Re-checking standard: InMon sFlow v5 specification says:
        # 4 bytes frameLength, 6 bytes srcMAC, 6 bytes dstMAC, 4 bytes type
        # No explicit padding mentioned between MACs in standard documentation for format=2.
        # So using 10:16 for destination_mac and 16:20 for type, assuming little/no padding.
        # But the original code used 12:18 for dest, and 20:24 for type, which suggests padding.
        # Let's stick to the original code's byte offsets for compatibility unless it causes issues.
        self.destination_mac = datagram[12:18].hex(":") # Original had 12:18
        self.type = unpack(">i", datagram[20:24])[0] # Original had 20:24

    def __repr__(self):
        return f"""
            Ethernet Frame:
                Frame Length: {self.frame_length}
                Source MAC: {self.source_mac}
                Destination MAC: {self.destination_mac}
                Frame Type: {self.type:#x} ({self.type})
        """


class sFlowSampledIpv4(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 3"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 32:
            raise ValueError("SampledIpv4 datagram too short.")
        self.length = unpack(">i", datagram[0:4])[0]
        self.protocol = unpack(">i", datagram[4:8])[0]
        self.source_ip = inet_ntop(AF_INET, datagram[8:12])
        self.destination_ip = inet_ntop(AF_INET, datagram[12:16])
        self.source_port = unpack(">i", datagram[16:20])[0]
        self.destination_port = unpack(">i", datagram[20:24])[0]
        self.tcp_flags = unpack(">i", datagram[24:28])[0]
        self.tos = unpack(">i", datagram[28:32])[0] # Type of Service (now DSCP+ECN)

    def __repr__(self):
        return f"""
            IPv4 Sample:
                Length: {self.length} (IP packet length)
                Protocol: {self.protocol}
                Source IP: {self.source_ip}
                Destination IP: {self.destination_ip}
                Source Port: {self.source_port}
                Destination Port: {self.destination_port}
                TCP Flags: {self.tcp_flags:#x} ({bin(self.tcp_flags)})
                Type of Service (ToS)/DSCP: {self.tos}
        """


class sFlowSampledIpv6(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 4"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 56:
            raise ValueError("SampledIpv6 datagram too short.")
        self.length = unpack(">i", datagram[0:4])[0]
        self.protocol = unpack(">i", datagram[4:8])[0]
        self.source_ip = inet_ntop(AF_INET6, datagram[8:24])
        self.destination_ip = inet_ntop(AF_INET6, datagram[24:40])
        self.source_port = unpack(">i", datagram[40:44])[0]
        self.destination_port = unpack(">i", datagram[44:48])[0]
        self.tcp_flags = unpack(">i", datagram[48:52])[0]
        self.priority = unpack(">i", datagram[52:56])[0] # Traffic Class

    def __repr__(self):
        return f"""
            IPv6 Sample:
                Length: {self.length} (IPv6 packet length)
                Next Header (Protocol): {self.protocol}
                Source IP: {self.source_ip}
                Destination IP: {self.destination_ip}
                Source Port: {self.source_port}
                Destination Port: {self.destination_port}
                TCP Flags: {self.tcp_flags:#x} ({bin(self.tcp_flags)})
                Traffic Class: {self.priority}
        """


class sFlowExtendedSwitch(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1001"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 16:
            raise ValueError("ExtendedSwitch datagram too short.")
        self.source_vlan = unpack(">i", datagram[0:4])[0]
        self.source_priority = unpack(">i", datagram[4:8])[0]
        self.destination_vlan = unpack(">i", datagram[8:12])[0]
        self.destination_priority = unpack(">i", datagram[12:16])[0]

    def __repr__(self):
        return f"""
            Extended Switch:
                Source VLAN: {self.source_vlan}
                Source Priority: {self.source_priority}
                Destination VLAN: {self.destination_vlan}
                Destination Priority: {self.destination_priority}
        """


class sFlowExtendedRouter(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1002"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 4:
            raise ValueError("ExtendedRouter datagram too short.")
        self.address_type = unpack(">i", datagram[0:4])[0]
        data_position = 4

        self.next_hop = None
        if self.address_type == SFLOW_ADDRESS_IPV4:
            if len(datagram) < data_position + 4: raise ValueError("ExtendedRouter datagram too short for IPv4 next hop.")
            self.next_hop = inet_ntop(AF_INET, datagram[data_position : data_position + 4])
            data_position += 4
        elif self.address_type == SFLOW_ADDRESS_IPV6:
            if len(datagram) < data_position + 16: raise ValueError("ExtendedRouter datagram too short for IPv6 next hop.")
            self.next_hop = inet_ntop(AF_INET6, datagram[data_position : data_position + 16])
            data_position += 16
        else:
            log.warning(f"Unknown address type {self.address_type} for ExtendedRouter next hop.")
            self.next_hop = "Unknown"
            self.source_mask_length = 0
            self.destination_mask_length = 0
            return # Exit early if address type is unknown

        if len(datagram) < data_position + 8:
            raise ValueError("ExtendedRouter datagram too short for mask lengths.")
        self.source_mask_length = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4
        self.destination_mask_length = unpack(">i", datagram[data_position : (data_position + 4)])[0]

    def __repr__(self):
        return f"""
            Extended Router:
                Next Hop Address: {self.next_hop} (Type: {self.address_type})
                Source Mask Length: {self.source_mask_length}
                Destination Mask Length: {self.destination_mask_length}
        """


class sFlowExtendedGateway(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1003"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 4:
            raise ValueError("ExtendedGateway datagram too short.")

        self.address_type = unpack(">i", datagram[0:4])[0]
        data_position = 4

        self.next_hop = None
        if self.address_type == SFLOW_ADDRESS_IPV4:
            if len(datagram) < data_position + 4: raise ValueError("ExtendedGateway datagram too short for IPv4 next hop.")
            self.next_hop = inet_ntop(AF_INET, datagram[data_position : data_position + 4])
            data_position += 4
        elif self.address_type == SFLOW_ADDRESS_IPV6:
            if len(datagram) < data_position + 16: raise ValueError("ExtendedGateway datagram too short for IPv6 next hop.")
            self.next_hop = inet_ntop(AF_INET6, datagram[data_position : data_position + 16])
            data_position += 16
        else:
            log.warning(f"Unknown address type {self.address_type} for ExtendedGateway next hop.")
            self.next_hop = "Unknown"
            self.asn = 0
            self.source_asn = 0
            self.source_peer_asn = 0
            self.as_path_type = 0
            self.as_path_count = 0
            self.destination_as_path = []
            self.community_count = 0
            self.communities = []
            self.local_preference = 0
            return

        if len(datagram) < data_position + 20: # For ASN, Source ASN, Source Peer ASN, AS Path Type, AS Path Count
            raise ValueError("ExtendedGateway datagram too short for core BGP attributes.")

        self.asn = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4
        self.source_asn = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4
        self.source_peer_asn = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4
        self.as_path_type = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4
        self.as_path_count = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4

        # Destination AS Path
        expected_path_size = self.as_path_count * 4
        if len(datagram) < data_position + expected_path_size:
            log.warning(f"ExtendedGateway datagram too short for AS path. Expected {expected_path_size}, got {len(datagram) - data_position}.")
            self.destination_as_path = []
            # Adjust data_position to skip corrupted part if possible or exit
            data_position += expected_path_size # Will likely go out of bounds
        else:
            self.destination_as_path = list(unpack(
                f'>{"i" * self.as_path_count}', datagram[data_position : (data_position + expected_path_size)]
            ))
            data_position += expected_path_size

        if len(datagram) < data_position + 4:
            log.warning("ExtendedGateway datagram too short for community count.")
            self.community_count = 0
            self.communities = []
            self.local_preference = 0
            return

        self.community_count = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4

        # Communities
        expected_communities_size = self.community_count * 4
        if len(datagram) < data_position + expected_communities_size:
            log.warning(f"ExtendedGateway datagram too short for communities. Expected {expected_communities_size}, got {len(datagram) - data_position}.")
            self.communities = []
            # Adjust data_position to skip corrupted part if possible or exit
            data_position += expected_communities_size # Will likely go out of bounds
        else:
            self.communities = list(unpack(
                f'>{"i" * self.community_count}', datagram[data_position : (data_position + expected_communities_size)]
            ))
            data_position += expected_communities_size

        if len(datagram) < data_position + 4:
            log.warning("ExtendedGateway datagram too short for local preference.")
            self.local_preference = 0
            return

        self.local_preference = unpack(">i", datagram[data_position : (data_position + 4)])[0]


    def __repr__(self):
        return f"""
            Extended Gateway:
                Next Hop Address: {self.next_hop}
                ASN: {self.asn}
                Source ASN: {self.source_asn}
                Source Peer ASN: {self.source_peer_asn}
                AS Path Type: {self.as_path_type}
                AS Path Count: {self.as_path_count}
                Destination AS Path: {self.destination_as_path}
                Community Count: {self.community_count}
                Communities: {self.communities}
                Local Preference: {self.local_preference}
        """


class sFlowExtendedUser(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1004"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 8:
            raise ValueError("ExtendedUser datagram too short.")

        self.source_character_set = unpack(">i", datagram[0:4])[0]
        name_length_src = unpack(">i", datagram[4:8])[0]
        data_position = 8

        if len(datagram) < data_position + name_length_src:
            raise ValueError("ExtendedUser datagram too short for source user string.")
        self.source_user = datagram[data_position : (data_position + name_length_src)].decode("utf-8", errors='replace')
        data_position += name_length_src
        # Padding to next 4-byte boundary
        data_position += (4 - (name_length_src % 4)) % 4

        if len(datagram) < data_position + 8:
            raise ValueError("ExtendedUser datagram too short for destination user info.")
        self.destination_character_set = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        name_length_dst = unpack(">i", datagram[data_position + 4 : data_position + 8])[0]
        data_position += 8

        if len(datagram) < data_position + name_length_dst:
            raise ValueError("ExtendedUser datagram too short for destination user string.")
        self.destination_user = datagram[data_position : (data_position + name_length_dst)].decode("utf-8", errors='replace')


    def __repr__(self):
        return f"""
            Extended User:
                Source Character Set: {self.source_character_set}
                Source User: {self.source_user}
                Destination Character Set: {self.destination_character_set}
                Destination User: {self.destination_user}
        """


class sFlowExtendedUrl(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1005"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 8:
            raise ValueError("ExtendedUrl datagram too short.")

        self.direction = unpack(">i", datagram[0:4])[0]
        url_length = unpack(">i", datagram[4:8])[0] # Length of the URL string
        data_position = 8

        if len(datagram) < data_position + url_length:
            raise ValueError("ExtendedUrl datagram too short for URL string.")
        self.url = datagram[data_position : (data_position + url_length)].decode("utf-8", errors='replace')
        data_position += url_length
        data_position += (4 - (url_length % 4)) % 4 # Padding

        if len(datagram) < data_position + 4:
            raise ValueError("ExtendedUrl datagram too short for host length.")
        host_length = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4

        if len(datagram) < data_position + host_length:
            raise ValueError("ExtendedUrl datagram too short for host string.")
        self.host = datagram[data_position : (data_position + host_length)].decode("utf-8", errors='replace')
        data_position += host_length
        data_position += (4 - (host_length % 4)) % 4 # Padding

        if len(datagram) < data_position + 4:
            raise ValueError("ExtendedUrl datagram too short for port name length.")
        port_name_length = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4

        if len(datagram) < data_position + port_name_length:
            raise ValueError("ExtendedUrl datagram too short for port name string.")
        self.port_name = datagram[data_position : (data_position + port_name_length)].decode("utf-8", errors='replace')

    def __repr__(self):
        return f"""
            Extended URL:
                URL: {self.url}
                Host: {self.host}
                Port Name: {self.port_name}
                Direction: {self.direction}
        """


class sFlowExtendedMpls(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1006"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 4:
            raise ValueError("ExtendedMpls datagram too short.")

        self.address_type = unpack(">i", datagram[0:4])[0]
        data_position = 4

        self.next_hop = None
        if self.address_type == SFLOW_ADDRESS_IPV4:
            if len(datagram) < data_position + 4: raise ValueError("ExtendedMpls datagram too short for IPv4 next hop.")
            self.next_hop = inet_ntop(AF_INET, datagram[data_position : (data_position + 4)])
            data_position += 4
        elif self.address_type == SFLOW_ADDRESS_IPV6:
            if len(datagram) < data_position + 16: raise ValueError("ExtendedMpls datagram too short for IPv6 next hop.")
            self.next_hop = inet_ntop(AF_INET6, datagram[data_position : (data_position + 16)])
            data_position += 16
        else:
            log.warning(f"Unknown address type {self.address_type} for ExtendedMpls next hop.")
            self.next_hop = "Unknown"
            self.in_label_stack_count = 0
            self.in_label_stack = []
            self.out_label_stack_count = 0
            self.out_label_stack = []
            return

        if len(datagram) < data_position + 4: raise ValueError("ExtendedMpls datagram too short for in label stack count.")
        self.in_label_stack_count = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4

        expected_in_stack_size = self.in_label_stack_count * 4 # Each label is 4 bytes
        if len(datagram) < data_position + expected_in_stack_size:
            log.warning(f"ExtendedMpls datagram too short for in label stack. Expected {expected_in_stack_size}, got {len(datagram) - data_position}.")
            self.in_label_stack = []
            data_position += expected_in_stack_size # Attempt to skip
        else:
            self.in_label_stack = list(unpack(
                f'>{"i" * self.in_label_stack_count}', datagram[data_position : (data_position + expected_in_stack_size)]
            ))
            data_position += expected_in_stack_size

        if len(datagram) < data_position + 4: raise ValueError("ExtendedMpls datagram too short for out label stack count.")
        self.out_label_stack_count = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4

        expected_out_stack_size = self.out_label_stack_count * 4 # Each label is 4 bytes
        if len(datagram) < data_position + expected_out_stack_size:
            log.warning(f"ExtendedMpls datagram too short for out label stack. Expected {expected_out_stack_size}, got {len(datagram) - data_position}.")
            self.out_label_stack = []
            # data_position += expected_out_stack_size # Attempt to skip
        else:
            self.out_label_stack = list(unpack(
                f'>{"i" * self.out_label_stack_count}', datagram[data_position : (data_position + expected_out_stack_size)]
            ))

    def __repr__(self):
        return f"""
            Extended MPLS:
                Next Hop: {self.next_hop} (Type: {self.address_type})
                In Label Stack Count: {self.in_label_stack_count}
                In Label Stack: {self.in_label_stack}
                Out Label Stack Count: {self.out_label_stack_count}
                Out Label Stack: {self.out_label_stack}
        """


class sFlowExtendedNat(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1007"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 4:
            raise ValueError("ExtendedNat datagram too short.")
        self.source_address_type = unpack(">i", datagram[0:4])[0]
        data_position = 4

        self.source_address = None
        if self.source_address_type == SFLOW_ADDRESS_IPV4:
            if len(datagram) < data_position + 4: raise ValueError("ExtendedNat datagram too short for IPv4 source address.")
            self.source_address = inet_ntop(AF_INET, datagram[data_position : (data_position + 4)])
            data_position += 4
        elif self.source_address_type == SFLOW_ADDRESS_IPV6:
            if len(datagram) < data_position + 16: raise ValueError("ExtendedNat datagram too short for IPv6 source address.")
            self.source_address = inet_ntop(AF_INET6, datagram[data_position : (data_position + 16)])
            data_position += 16
        else:
            log.warning(f"Unknown source address type {self.source_address_type} for ExtendedNat.")
            self.source_address = "Unknown"
            self.destination_address = "Unknown"
            return

        if len(datagram) < data_position + 4: raise ValueError("ExtendedNat datagram too short for destination address type.")
        self.destination_address_type = unpack(">i", datagram[data_position : data_position + 4])[0]
        data_position += 4

        self.destination_address = None
        if self.destination_address_type == SFLOW_ADDRESS_IPV4:
            if len(datagram) < data_position + 4: raise ValueError("ExtendedNat datagram too short for IPv4 destination address.")
            self.destination_address = inet_ntop(AF_INET, datagram[data_position : (data_position + 4)])
            data_position += 4
        elif self.destination_address_type == SFLOW_ADDRESS_IPV6:
            if len(datagram) < data_position + 16: raise ValueError("ExtendedNat datagram too short for IPv6 destination address.")
            self.destination_address = inet_ntop(AF_INET6, datagram[data_position : (data_position + 16)])
            data_position += 16
        else:
            log.warning(f"Unknown destination address type {self.destination_address_type} for ExtendedNat.")
            self.destination_address = "Unknown"


    def __repr__(self):
        return f"""
            Extended NAT:
                Source Address (Type {self.source_address_type}): {self.source_address}
                Destination Address (Type {self.destination_address_type}): {self.destination_address}
        """


class sFlowExtendedMplsTunnel(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1008"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 8:
            raise ValueError("ExtendedMplsTunnel datagram too short.")
        name_length = unpack(">i", datagram[0:4])[0] # Length of host string
        data_position = 4

        if len(datagram) < data_position + name_length:
            raise ValueError("ExtendedMplsTunnel datagram too short for host string.")
        self.host = datagram[data_position : (data_position + name_length)].decode("utf-8", errors='replace')
        data_position += name_length
        data_position += (4 - (name_length % 4)) % 4 # Padding

        if len(datagram) < data_position + 8:
            raise ValueError("ExtendedMplsTunnel datagram too short for tunnel ID/COS.")
        self.tunnel_id = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4
        self.tunnel_cos = unpack(">i", datagram[data_position : (data_position + 4)])[0]

    def __repr__(self):
        return f"""
            Extended MPLS Tunnel:
                Host: {self.host}
                Tunnel ID: {self.tunnel_id}
                Tunnel COS: {self.tunnel_cos}
        """


class sFlowExtendedMplsVc(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1009"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 8:
            raise ValueError("ExtendedMplsVc datagram too short.")
        name_length = unpack(">i", datagram[0:4])[0] # Length of VC instance name string
        data_position = 4

        if len(datagram) < data_position + name_length:
            raise ValueError("ExtendedMplsVc datagram too short for VC instance name string.")
        self.vc_instance_name = datagram[data_position : (data_position + name_length)].decode("utf-8", errors='replace')
        data_position += name_length
        data_position += (4 - (name_length % 4)) % 4 # Padding

        if len(datagram) < data_position + 8:
            raise ValueError("ExtendedMplsVc datagram too short for VLL VC ID/Label COS.")
        self.vll_vc_id = unpack(">i", datagram[data_position : (data_position + 4)])[0]
        data_position += 4
        self.vc_label_cos = unpack(">i", datagram[data_position : (data_position + 4)])[0]

    def __repr__(self):
        return f"""
            Extended MPLS Virtual Circuit:
                VC Instance Name: {self.vc_instance_name}
                VLL VC ID: {self.vll_vc_id}
                VC Label COS: {self.vc_label_cos}
        """


class sFlowExtendedMpls_FTN(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1010"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 8:
            raise ValueError("ExtendedMpls_FTN datagram too short.")
        name_length = unpack(">i", datagram[0:4])[0] # Length of description string
        data_position = 4

        if len(datagram) < data_position + name_length:
            raise ValueError("ExtendedMpls_FTN datagram too short for description string.")
        self.mpls_ftn_description = datagram[data_position : (data_position + name_length)].decode("utf-8", errors='replace')
        data_position += name_length
        data_position += (4 - (name_length % 4)) % 4 # Padding

        if len(datagram) < data_position + 4:
            raise ValueError("ExtendedMpls_FTN datagram too short for MPLS FTN mask.")
        self.mpls_ftn_mask = unpack(">i", datagram[data_position : (data_position + 4)])[0]

    def __repr__(self):
        return f"""
            Extended MPLS FTN:
                Description: {self.mpls_ftn_description}
                Mask: {self.mpls_ftn_mask}
        """


class sFlowExtendedMpls_LDP_FEC(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1011"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 4:
            raise ValueError("ExtendedMpls_LDP_FEC datagram too short.")
        self.mpls_fec_address_prefix_length = unpack(">i", datagram[0:4])[0]

    def __repr__(self):
        return f"""
            Extended MPLS LDP FEC:
                LDP FEC Address Prefix Length: {self.mpls_fec_address_prefix_length}
        """


class sFlowExtendedVlantunnel(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 1012"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 4:
            raise ValueError("ExtendedVlantunnel datagram too short.")
        stack_count = unpack(">i", datagram[0:4])[0]
        data_position = 4
        
        expected_stack_size = stack_count * 4 # Each VLAN ID is 4 bytes
        if len(datagram) < data_position + expected_stack_size:
            log.warning(f"ExtendedVlantunnel datagram too short for VLAN stack. Expected {expected_stack_size}, got {len(datagram) - data_position}.")
            self.stack = []
        else:
            self.stack = list(unpack(f'>{"i" * stack_count}', datagram[data_position : (data_position + expected_stack_size)]))

    def __repr__(self):
        return f"""
            Extended VLAN Tunnel:
                Stack: {self.stack}
        """


class sFlowExtendedSocketIpv4(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 2100"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 20:
            raise ValueError("ExtendedSocketIpv4 datagram too short.")
        self.protocol = unpack(">i", datagram[0:4])[0]
        self.local_ip = inet_ntop(AF_INET, datagram[4:8])
        self.remote_ip = inet_ntop(AF_INET, datagram[8:12])
        self.local_port = unpack(">i", datagram[12:16])[0]
        self.remote_port = unpack(">i", datagram[16:20])[0]

    def __repr__(self):
        return f"""
            Extended IPv4 Socket:
                Protocol: {self.protocol}
                Local IP: {self.local_ip}
                Local Port: {self.local_port}
                Remote IP: {self.remote_ip}
                Remote Port: {self.remote_port}
        """


class sFlowExtendedSocketIpv6(sFlowRecordBase):
    """Flow Data: enterprise = 0, format = 2101"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        if len(datagram) < 44:
            raise ValueError("ExtendedSocketIpv6 datagram too short.")
        self.protocol = unpack(">i", datagram[0:4])[0]
        self.local_ip = inet_ntop(AF_INET6, datagram[4:20])
        self.remote_ip = inet_ntop(AF_INET6, datagram[20:36])
        self.local_port = unpack(">i", datagram[36:40])[0]
        self.remote_port = unpack(">i", datagram[40:44])[0]

    def __repr__(self):
        return f"""
            Extended IPv6 Socket:
                Protocol: {self.protocol}
                Local IP: {self.local_ip}
                Local Port: {self.local_port}
                Remote IP: {self.remote_ip}
                Remote Port: {self.remote_port}
        """


# --- Counter Record Types ---

class sFlowIfCounters(sFlowRecordBase):
    """Counter Data: enterprise = 0, format = 1 (ifMib_ifEntry compatible)"""
    def __init__(self, datagram: bytes):
        super().__init__(datagram)
        # Based on ifMib_ifEntry from RFC 2863 and sFlow v5 specification
        # Requires 28 * 4 (for ints) + 1 * 8 (for speed) = 120 bytes minimum for all fields.
        # Original code was truncated. Completing based on sFlow v5 spec.
        # Total 20 32-bit fields and 1 64-bit field, so 21 fields.
        # But RFC 2863 ifEntry has more. Let's stick to common sFlow interpretation (21 fields).

        # Check for minimum expected size
        if len(datagram) < calcsize('>iiiq16i'): # Minimum for index, type, speed, direction, status + 16 more ints
            log.warning(f"sFlowIfCounters datagram too short. Expected at least {calcsize('>iiiq16i')} bytes, got {len(datagram)}. Some fields may be missing.")

        current_pos = 0
        try:
            self.index = unpack(">i", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.type = unpack(">i", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.speed = unpack(">q", datagram[current_pos : current_pos + 8])[0] # 64-bit
            current_pos += 8
            self.direction = unpack(">i", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.status = unpack(">i", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.in_octets = unpack(">Q", datagram[current_pos : current_pos + 8])[0] # 64-bit unsigned
            current_pos += 8
            self.in_ucast_pkts = unpack(">I", datagram[current_pos : current_pos + 4])[0] # 32-bit unsigned
            current_pos += 4
            self.in_multicast_pkts = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.in_broadcast_pkts = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.in_discards = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.in_errors = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.in_unknown_protocols = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.out_octets = unpack(">Q", datagram[current_pos : current_pos + 8])[0] # 64-bit unsigned
            current_pos += 8
            self.out_ucast_pkts = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.out_multicast_pkts = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.out_broadcast_pkts = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.out_discards = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.out_errors = unpack(">I", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
            self.promiscuous_mode = unpack(">i", datagram[current_pos : current_pos + 4])[0]
            current_pos += 4
        except Exception as e:
            log.warning(f"Partial sFlowIfCounters parsing due to data length or format mismatch: {e}")
            # Set remaining attributes to None or default if parsing failed mid-way
            attrs = ['status', 'in_octets', 'in_ucast_pkts', 'in_multicast_pkts', 'in_broadcast_pkts',
                     'in_discards', 'in_errors', 'in_unknown_protocols', 'out_octets',
                     'out_ucast_pkts', 'out_multicast_pkts', 'out_broadcast_pkts',
                     'out_discards', 'out_errors', 'promiscuous_mode']
            for attr in attrs:
                if not hasattr(self, attr):
                    setattr(self, attr, None) # Or 0, depending on desired default

    def __repr__(self):
        return f"""
            Interface Counters:
                Index: {self.index}
                Type: {self.type}
                Speed: {self.speed} bps
                Direction: {self.direction}
                Status: {self.status}
                In Octets: {self.in_octets}
                In Unicast Packets: {self.in_ucast_pkts}
                In Multicast Packets: {self.in_multicast_pkts}
                In Broadcast Packets: {self.in_broadcast_pkts}
                In Discards: {self.in_discards}
                In Errors: {self.in_errors}
                In Unknown Protocols: {self.in_unknown_protocols}
                Out Octets: {self.out_octets}
                Out Unicast Packets: {self.out_ucast_pkts}
                Out Multicast Packets: {self.out_multicast_pkts}
                Out Broadcast Packets: {self.out_broadcast_pkts}
                Out Discards: {self.out_discards}
                Out Errors: {self.out_errors}
                Promiscuous Mode: {self.promiscuous_mode}
        """

# --- Mapping Dictionary for Records ---
# This dictionary maps (sample_type, enterprise, format) to the corresponding class.
# Enterprise 0 is for standard sFlow types.
s_flow_record_format = {
    # Flow Data Records (Sample Types 1 and 3)
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_RAW_PACKET_HEADER): sFlowRawPacketHeader,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_RAW_PACKET_HEADER): sFlowRawPacketHeader,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_ETHERNET_FRAME): sFlowEthernetFrame,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_ETHERNET_FRAME): sFlowEthernetFrame,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_SAMPLED_IPV4): sFlowSampledIpv4,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_SAMPLED_IPV4): sFlowSampledIpv4,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_SAMPLED_IPV6): sFlowSampledIpv6,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_SAMPLED_IPV6): sFlowSampledIpv6,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_SWITCH): sFlowExtendedSwitch,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_SWITCH): sFlowExtendedSwitch,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_ROUTER): sFlowExtendedRouter,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_ROUTER): sFlowExtendedRouter,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_GATEWAY): sFlowExtendedGateway,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_GATEWAY): sFlowExtendedGateway,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_USER): sFlowExtendedUser,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_USER): sFlowExtendedUser,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_URL): sFlowExtendedUrl,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_URL): sFlowExtendedUrl,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_MPLS): sFlowExtendedMpls,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_MPLS): sFlowExtendedMpls,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_NAT): sFlowExtendedNat,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_NAT): sFlowExtendedNat,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_MPLS_TUNNEL): sFlowExtendedMplsTunnel,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_MPLS_TUNNEL): sFlowExtendedMplsTunnel,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_MPLS_VC): sFlowExtendedMplsVc,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_MPLS_VC): sFlowExtendedMplsVc,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_MPLS_FTN): sFlowExtendedMpls_FTN,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_MPLS_FTN): sFlowExtendedMpls_FTN,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_MPLS_LDP_FEC): sFlowExtendedMpls_LDP_FEC,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_MPLS_LDP_FEC): sFlowExtendedMpls_LDP_FEC,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_VLAN_TUNNEL): sFlowExtendedVlantunnel,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_VLAN_TUNNEL): sFlowExtendedVlantunnel,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_SOCKET_IPV4): sFlowExtendedSocketIpv4,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_SOCKET_IPV4): sFlowExtendedSocketIpv4,
    (SFLOW_FLOW_SAMPLE, 0, SFLOW_FLOW_EXT_SOCKET_IPV6): sFlowExtendedSocketIpv6,
    (SFLOW_FLOW_SAMPLE_EXPANDED, 0, SFLOW_FLOW_EXT_SOCKET_IPV6): sFlowExtendedSocketIpv6,

    # Counter Data Records (Sample Types 2 and 4)
    (SFLOW_COUNTER_SAMPLE, 0, SFLOW_COUNTER_IF): sFlowIfCounters,
    (SFLOW_COUNTER_SAMPLE_EXPANDED, 0, SFLOW_COUNTER_IF): sFlowIfCounters,
    # Add other counter record types as implemented
}


class sFlowRecord:
    """
    Represents an sFlow record contained within an sFlow sample.
    Dispatches to specific record parsing classes based on header and sample type.
    """
    def __init__(self, header: bytes, sample_type: int, datagram: bytes):
        self.header_raw = header
        self.sample_type = sample_type # Keep track of the parent sample type for dispatch
        self.enterprise, self.format = divmod(unpack(">i", header)[0], 4096)
        self.datagram = datagram

        # Get the appropriate record class from the mapping, default to sFlowRecordBase
        record_class = s_flow_record_format.get((self.sample_type, self.enterprise, self.format), sFlowRecordBase)
        try:
            self.record = record_class(datagram)
        except Exception as e:
            log.error(f"Error parsing sFlow record type {self.enterprise}-{self.format} (sample type {self.sample_type}): {e}")
            self.record = sFlowRecordBase(datagram) # Fallback to base if specific parsing fails
